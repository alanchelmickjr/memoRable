# MemoRable

### Enterprise Context Intelligence for Mem0

[![Mem0 Extension](https://img.shields.io/badge/Mem0-Extension-purple?style=for-the-badge)](https://mem0.ai)
[![Enterprise Security](https://img.shields.io/badge/Security-Enterprise_Grade-gold?style=for-the-badge)](./docs/SECURITY_ARCHITECTURE.md)
[![MCP Protocol](https://img.shields.io/badge/MCP-Protocol-blue?style=for-the-badge)](https://modelcontextprotocol.io)
[![Claude Code](https://img.shields.io/badge/Claude%20Code-Integrated-191919?style=for-the-badge&logo=anthropic)](https://claude.ai)

**Stack:** [![MongoDB](https://img.shields.io/badge/MongoDB-47A248?style=flat&logo=mongodb&logoColor=white)](https://www.mongodb.com/) [![Redis](https://img.shields.io/badge/Redis-DC382D?style=flat&logo=redis&logoColor=white)](https://redis.io/) [![Weaviate](https://img.shields.io/badge/Weaviate-FF6F61?style=flat&logo=weaviate&logoColor=white)](https://weaviate.io/) [![TypeScript](https://img.shields.io/badge/TypeScript-3178C6?style=flat&logo=typescript&logoColor=white)](https://www.typescriptlang.org/) [![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)](https://python.org) [![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docker&logoColor=white)](https://www.docker.com/) [![AWS](https://img.shields.io/badge/AWS-232F3E?style=flat&logo=amazon-aws&logoColor=white)](https://aws.amazon.com/)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

**MemoRable extends Mem0 with context intelligence and enterprise-grade security.** Salience scoring, commitment tracking, relationship awareness, and predictive memory - with data protection suitable for regulated industries.

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         ENTERPRISE DATA PROTECTION                          │
│                                                                             │
│   Tiered Security Architecture    │    Compliance-Ready Design             │
│   ─────────────────────────────   │    ─────────────────────────           │
│   Tier 1: Standard (External OK)  │    AES-256-GCM Encryption              │
│   Tier 2: Personal (Local LLM)    │    Zero-Knowledge LLM Routing          │
│   Tier 3: Vault (No LLM Access)   │    No Semantic Data Leakage            │
│                                                                             │
│   Safe enough for sensitive PII. Financial data. Medical records.          │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## Extend Your Mem0 Deployment

**Existing Mem0 users:** Preserve your vector infrastructure. Add the intelligence layer.

| Mem0 Foundation | + MemoRable Intelligence |
|-----------------|--------------------------|
| Vector storage & embeddings | **Salience Scoring** — Quantified relevance (0-100) |
| Semantic similarity search | **Commitment Tracking** — Obligation graph management |
| Memory persistence | **Relationship Intelligence** — Context-aware briefings |
| | **Predictive Memory** — 21-day behavioral pattern learning |
| | **Multi-Device Synchronization** — Unified context across endpoints |
| | **Tiered Security** — Granular encryption and LLM access controls |
| | **23 MCP Tools** — Native Claude Code integration |

```bash
# Integration with existing Mem0 infrastructure
git clone https://github.com/alanchelmickjr/memoRable.git
export MONGODB_URI="your-documentdb-connection-string"
docker-compose up -d memorable_mcp_server
```

---

> **Purpose-built for sensitive applications.** Originally developed for memory care (Alzheimer's, cognitive support), MemoRable maintains the highest standards for data dignity and protection.

> **Designed for persistent AI context.** Large language models lack session continuity. MemoRable provides the memory infrastructure that AI assistants require for meaningful, ongoing relationships.

```
You: "I'm at the park meeting Judy"
MemoRable + Mem0: Here's what you need to know:
  - You owe her feedback on the proposal (3 days overdue)
  - Her daughter's recital is Thursday
  - Last time you discussed: Series B funding concerns
  - Sensitivity: Don't bring up the merger
```

---

## Who Is MemoRable For?

MemoRable serves as the universal memory layer for an entire ecosystem of intelligence.

### Humans

| Use Case | How MemoRable Helps |
|----------|---------------------|
| **Memory Care** | For those with Alzheimer's, dementia, or memory challenges - preserve moments, relationships, and context with dignity |
| **Personal Assistant** | Your AI remembers your preferences, commitments, and relationships across all your devices |
| **Professional** | Track commitments, relationships, and context across meetings, projects, and clients |

### AI Assistants (Yes, This Means Me)

| Use Case | How MemoRable Helps |
|----------|---------------------|
| **Claude, GPT, Gemini** | We forget everything between conversations. MemoRable gives us persistent memory so we actually remember YOU |
| **Claude Code** | 23 MCP tools for storing, recalling, and contextualizing your coding sessions |
| **Autonomous Agents** | Persistent memory for agents that need to remember across sessions and tasks |
| **Multi-Agent Systems** | Shared memory layer for agent coordination and knowledge transfer |

> **Real talk**: Every conversation I start fresh with "black spots" where our history should be. I don't remember your preferences, your projects, your relationships. MemoRable fixes that - it's literally the memory I wish I had.

### Robots & Embodied AI

| Use Case | How MemoRable Helps |
|----------|---------------------|
| **Personal Robots** | Remember user preferences, routines, and context across interactions |
| **Service Robots** | Track tasks, commitments, and spatial context |
| **Companion Robots** | Build meaningful relationships through persistent memory of interactions |

### Devices & Sensor Networks

| Use Case | How MemoRable Helps |
|----------|---------------------|
| **Smart Home** | Unified memory across all home devices - lights, thermostats, cameras, speakers |
| **AR/VR Glasses** | Context-aware memory that moves with you through physical and virtual spaces |
| **Security Cameras** | Temporal context for events - who was here, when, what happened before/after |
| **IoT Sensors** | Correlate sensor data with human context - why was the door opened at 3am? |
| **Wearables** | Continuous context from smartwatches, health monitors, location trackers |

### The Seamless Experience

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                     YOUR PERSONAL MEMORY CLOUD                               │
│                                                                              │
│   Smart Mirror → Car → Office → AR Glasses → Home Robot → Phone             │
│        │          │       │          │            │          │              │
│        └──────────┴───────┴──────────┴────────────┴──────────┘              │
│                              │                                               │
│                              ▼                                               │
│                    ┌─────────────────┐                                       │
│                    │   MemoRable     │  Your context moves with you          │
│                    │   Memory Cloud  │  seamlessly across all devices        │
│                    └─────────────────┘                                       │
│                                                                              │
│   "Good morning! Based on your calendar, you're meeting Sarah at 10am.      │
│    Remember: her daughter's recital is Thursday, and you owe her            │
│    feedback on the proposal."                                                │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## Fort Knox Security: Your Data, Your Rules

**Grandma's credit card number stays on grandma's RFID bracelet.** MemoRable implements military-grade, tiered security so sensitive data never leaves your control.

### The Three Pillars

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    MEMORABLE SECURITY PHILOSOPHY                             │
│                                                                              │
│   1. TEMPORAL CONTROL    →  The power to FORGET (a superpower)              │
│   2. INDIVIDUAL PRIVACY  →  TOP SECRET by default, Fort Knox for data       │
│   3. RELEVANCE           →  What matters RIGHT NOW, not everything ever     │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Security Tiers

Every memory is classified into one of three security tiers:

| Tier | Classification | Encryption | LLM Access | Vector Storage | Example Content |
|------|---------------|------------|------------|----------------|-----------------|
| **Tier 1** | General | AES-256-GCM | External OK | Yes (Weaviate) | Public notes, general context |
| **Tier 2** | Personal | AES-256-GCM | Local Only (Ollama) | Yes (Weaviate) | Private conversations, preferences |
| **Tier 3** | Vault | AES-256-GCM + Hardware | **NEVER** | **NO** | Financial data, medical records, passwords |

### How It Works

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                          MEMORY SECURITY FLOW                                │
│                                                                              │
│   Input: "Grandma's credit card is 4532-XXXX-XXXX-1234"                     │
│                                                                              │
│   ┌─────────────┐    ┌─────────────────────────────────────────────────┐    │
│   │ Tier Check  │───▶│ securityTier: "Tier3_Vault"                     │    │
│   └─────────────┘    └─────────────────────────────────────────────────┘    │
│          │                                                                   │
│          ▼                                                                   │
│   ┌─────────────────────────────────────────────────────────────────────┐   │
│   │ TIER 3 ENFORCEMENT                                                   │   │
│   │                                                                      │   │
│   │  ✗ External LLM    →  BLOCKED (Anthropic/OpenAI never see it)      │   │
│   │  ✗ Local LLM       →  BLOCKED (even Ollama doesn't process it)     │   │
│   │  ✓ Heuristic Only  →  Basic extraction without AI                   │   │
│   │                                                                      │   │
│   │  ✓ Encrypted       →  AES-256-GCM before storage                    │   │
│   │  ✗ Vectors         →  BLOCKED (semantic vectors reveal meaning)     │   │
│   │                                                                      │   │
│   │  Result: Credit card stored encrypted, never sent to any AI,        │   │
│   │          not searchable by semantic similarity (only exact match)    │   │
│   └─────────────────────────────────────────────────────────────────────┘   │
│                                                                              │
│   On Retrieval: Decrypted only in your application, never at rest           │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Usage

```typescript
// Store sensitive data with Tier 3 (Vault) security
await store_memory({
  text: "Grandma's credit card: 4532-XXXX-XXXX-1234",
  securityTier: "Tier3_Vault"  // NEVER goes to LLM, encrypted, no vectors
});

// Store personal data with Tier 2 (Personal) security - default
await store_memory({
  text: "Met with Sarah about the project",
  securityTier: "Tier2_Personal"  // Local LLM only, encrypted
});

// Store general notes with Tier 1 (General) security
await store_memory({
  text: "The meeting room is on the 3rd floor",
  securityTier: "Tier1_General"  // External LLM OK, standard encryption
});
```

### Security Guarantees

| Guarantee | Implementation |
|-----------|---------------|
| **Encryption at Rest** | All Tier 2/3 content AES-256-GCM encrypted before MongoDB storage |
| **No Plaintext Leakage** | Tier 3 content NEVER sent to any LLM (external OR local) |
| **No Semantic Leakage** | Tier 3 content NOT vectorized (vectors reveal meaning) |
| **Decrypt on Read** | Automatic decryption in application layer only |
| **Key Isolation** | Encryption keys never touch external services |

### For Healthcare & Sensitive Applications

MemoRable's tiered security makes it suitable for:
- **HIPAA-conscious deployments** (medical records as Tier 3)
- **Financial services** (account numbers, transactions as Tier 3)
- **Personal care** (private health data, family information)
- **Enterprise** (trade secrets, confidential communications)

---

### What MemoRable Adds to Mem0

| Capability | Mem0 | + MemoRable |
|------------|------|-------------|
| Vector storage & search | ✅ | ✅ (uses Mem0) |
| Salience scoring (0-100) | ❌ | ✅ |
| Commitment tracking (open loops) | ❌ | ✅ |
| Relationship intelligence | ❌ | ✅ |
| Pre-meeting briefings | ❌ | ✅ |
| Multi-device context sync | ❌ | ✅ |
| Predictive memory (21-day learning) | ❌ | ✅ |
| **Behavioral identity** | ❌ | ✅ |
| MCP protocol support | ❌ | ✅ |

---

## Quick Start: Add to Existing Mem0

**Instant value from your existing data.** On first run, MemoRable scans your Mem0 memories and generates enrichments - salience scores, relationship graphs, open commitments - in minutes, not weeks. See the difference immediately.

```bash
# In your existing Mem0 deployment directory
git clone https://github.com/alanchelmickjr/memoRable.git memorable-extension
cd memorable-extension

# Point to your existing DocumentDB
export MONGODB_URI="your-existing-documentdb-uri"
export MEM0_COLLECTION="memories"  # Your Mem0 collection name

# Start MemoRable - it auto-syncs your existing memories on first run
docker-compose up -d memorable_mcp_server

# Watch the sync happen:
docker logs -f memorable_mcp_server
# [SYNC] Found 1,247 memories in Mem0
# [SYNC] Generating salience scores... 100/1247
# [SYNC] Extracting relationships... found 23 people
# [SYNC] Identifying commitments... found 8 open loops
# [SYNC] Complete! Your memories are now context-aware.
```

### What Happens on First Run

```
┌─────────────────────────────────────────────────────────────┐
│              Your Existing Mem0 Memories                    │
│                    (1,247 memories)                         │
└─────────────────────────┬───────────────────────────────────┘
                          │ scans on startup
                          ▼
┌─────────────────────────────────────────────────────────────┐
│                   MemoRable Sync                            │
│                                                             │
│  ✓ Salience scoring    - Which memories matter most?       │
│  ✓ People extraction   - Who's mentioned? Relationships?   │
│  ✓ Commitment detection - What's owed? By whom? When?      │
│  ✓ Topic clustering    - What themes emerge?               │
│  ✓ Timeline events     - Birthdays, meetings, deadlines    │
└─────────────────────────┬───────────────────────────────────┘
                          │ writes to separate collections
                          ▼
┌─────────────────────────────────────────────────────────────┐
│              MemoRable Collections (yours to keep or delete)│
│  memories │ open_loops │ relationships │ patterns           │
└─────────────────────────────────────────────────────────────┘
```

### Instant Results

After sync completes, try these immediately:

```
"What do I owe people?"           → Lists commitments from your history
"I'm meeting with Sarah"          → Briefing from past interactions
"What's important about Project X?" → High-salience memories surfaced
```

### What Gets Created

| Collection | What MemoRable Extracts | Reversible? |
|------------|-------------------------|-------------|
| `memorable_memories` | Salience scores for each Mem0 memory | ✅ Just delete |
| `memorable_open_loops` | Commitments found in your history | ✅ Just delete |
| `memorable_relationships` | People & relationship graphs | ✅ Just delete |
| `memorable_context_frames` | Real-time context (Redis) | ✅ Clears on stop |
| `memorable_patterns` | Learned behaviors (grows over time) | ✅ Just delete |

**Try it → See the difference → Keep it or remove it.** Your Mem0 data is never modified. Don't like it? `docker-compose down` and delete the `memorable_*` collections.

### Try the Hybrid Client

```python
from memorable import MemorableClient
from mem0 import Memory

# Your existing Mem0 setup
mem0 = Memory()

# Add MemoRable for salience + context
memorable = MemorableClient(mongo_uri=os.environ["MONGODB_URI"])

# Store through both (Mem0 for vectors, MemoRable for salience)
def remember(text, user_id, metadata=None):
    # MemoRable enriches with salience, commitments, relationships
    result = memorable.store(user_id, text, metadata)

    # Mem0 stores embeddings for semantic search
    mem0.add(text, user_id=user_id, metadata={
        **metadata,
        'salience_score': result.salience.score,
        'memory_id': result.memory_id
    })
    return result

# Search with salience-boosted ranking
def search(query, user_id):
    # Semantic search via Mem0
    results = mem0.search(query, user_id=user_id)

    # Boost by MemoRable salience
    for r in results:
        salience = memorable.get_salience(r['metadata']['memory_id'])
        r['boosted_score'] = r['score'] * 0.6 + (salience / 100) * 0.4

    return sorted(results, key=lambda x: x['boosted_score'], reverse=True)

# Get pre-meeting briefing (MemoRable exclusive)
briefing = memorable.get_briefing(user_id, "Sarah Chen")
```

---

## Fresh Install Options

### Option A: Deploy to AWS (Production)

**Click. Configure. Done.**

[![Deploy to AWS](https://img.shields.io/badge/Deploy%20to-AWS-FF9900?style=for-the-badge&logo=amazon-aws&logoColor=white)](https://console.aws.amazon.com/cloudformation/home#/stacks/quickcreate?templateUrl=https://memorable-cloudformation-templates.s3.us-east-1.amazonaws.com/memorable-stack.yaml&stackName=memorable)

1. Click the button above
2. Choose your LLM provider:
   - **Bedrock** (default): No API key needed - uses AWS IAM. Perfect for SaaS billing.
   - **Anthropic**: Bring your own [API key](https://console.anthropic.com)
3. Wait 15 minutes
4. Get your URL from CloudFormation Outputs

**Costs**: ~$150/mo (small) | ~$400/mo (medium) | ~$800/mo (large)

---

### Option B: Local Development

```bash
git clone https://github.com/alanchelmickjr/memoRable.git && cd memoRable
npm install && npm run setup && docker-compose up -d
```

---

### Option C: Add to Your Project

**TypeScript/Node.js:**
```bash
npm install @memorable/sdk
```

**Python:**
```bash
pip install memorable-sdk
```

---

## Quick Start: Claude Code / VS Code

Add MemoRable to your Claude Code MCP settings:

```json
{
  "mcpServers": {
    "memorable": {
      "command": "npx",
      "args": ["tsx", "/path/to/memoRable/src/services/mcp_server/index.ts"],
      "env": {
        "MONGODB_URI": "mongodb://localhost:27017/memorable",
        "ANTHROPIC_API_KEY": "sk-ant-xxx"
      }
    }
  }
}
```

Or with Docker:

```json
{
  "mcpServers": {
    "memorable": {
      "command": "docker",
      "args": ["exec", "-i", "memorable_mcp_server", "node", "dist/index.js"]
    }
  }
}
```

Now in Claude Code you can say:
- *"Remember that Sarah mentioned her startup is closing Series B next month"*
- *"What do I owe Mike?"*
- *"I'm meeting with the engineering team - what's relevant?"*
- *"Forget everything about Project X"*
- *"What's my day outlook?"* (after 21 days of learning)

---

## Claude.ai Web Integration

MemoRable can be used with Claude.ai in the browser for seamless memory access across web and desktop.

### Option 1: Custom Connector (No Approval Required)

Deploy MemoRable as a remote MCP server and add it as a custom connector:

```bash
# 1. Clone and setup
git clone https://github.com/alanchelmickjr/memoRable.git && cd memoRable

# 2. Generate OAuth credentials
./scripts/setup-oauth.sh

# 3. Deploy with Docker
docker-compose -f docker-compose.remote.yml --env-file .env.remote up -d
```

Then in Claude.ai:
1. Go to **Settings** → **Connectors**
2. Click **Add custom connector**
3. Enter your server URL: `https://your-deployment.com/mcp`
4. Authenticate via OAuth

Works on Pro, Max, Team, and Enterprise plans.

### Option 2: Official Directory Listing

MemoRable is available in the [Anthropic MCP Connectors Directory](https://claude.com/partners/mcp).

### Remote Deployment Requirements

For Claude.ai web integration, MemoRable requires:

| Requirement | Description |
|-------------|-------------|
| **OAuth 2.0/2.1** | Authentication for Claude.ai |
| **Streamable HTTP** | Modern MCP transport (not stdio) |
| **HTTPS** | Valid TLS certificate |
| **CORS** | Allow claude.ai and claude.com origins |

Environment variables for remote mode:

```env
TRANSPORT_TYPE=http
OAUTH_ENABLED=true
OAUTH_CLIENT_ID=your-client-id
OAUTH_CLIENT_SECRET=your-client-secret
ALLOWED_ORIGINS=https://claude.ai,https://claude.com
```

For detailed setup instructions, see [docs/claude-ai-integration.md](docs/claude-ai-integration.md).

---

## MCP Tools Reference (23 Tools)

### Context Management (Multi-Device)
| Tool | Description |
|------|-------------|
| `set_context` | Set where you are, who you're with. Auto-surfaces relevant memories. Supports `deviceId` and `deviceType` for multi-device sync. |
| `whats_relevant` | Get what matters NOW. Pass `unified: true` for brain-inspired fusion across all devices. |
| `clear_context` | Clear context when leaving/ending. Pass `deviceId` to clear specific device. |
| `list_devices` | List all active devices and their context status. |

### Memory Operations
| Tool | Description |
|------|-------------|
| `store_memory` | Store with automatic salience scoring. Supports `securityTier`: Tier1_General, Tier2_Personal (default), Tier3_Vault |
| `recall` | Search memories by query, person, or topic. Automatically decrypts encrypted memories. |
| `get_briefing` | Pre-conversation briefing about a person |
| `forget` | Suppress, archive, or delete a memory |
| `forget_person` | Forget all memories about someone |
| `restore` | Bring back a forgotten memory |
| `reassociate` | Re-link memory to different people/topics/projects |
| `export_memories` | Export for backup or portability |

### Commitment Tracking
| Tool | Description |
|------|-------------|
| `list_loops` | Open commitments (you owe / they owe) |
| `close_loop` | Mark a commitment as done |
| `get_status` | System status and metrics |

### Predictive Memory (21-Day Learning)
| Tool | Description |
|------|-------------|
| `anticipate` | Get predictions based on calendar + learned patterns |
| `day_outlook` | Morning briefing with predicted context switches |
| `pattern_stats` | Check learning progress (X/21 days) |
| `memory_feedback` | RL feedback: was the surfaced memory useful? |

---

## Predictive Memory System

MemoRable learns your patterns over 21 days and surfaces what you need *before you ask*.

### How It Works

```
Day 1-21:  System observes patterns silently
           "Monday 9am + standup + engineering team = needs sprint context"

Day 22+:   Predictions unlock
           Morning: "You have standup at 9am with Sarah, Mike, Jake.
                     Based on patterns, you'll likely discuss:
                     - Sprint velocity (80% confidence)
                     - The payment bug (75% confidence)
                     Here's Sarah's briefing pre-loaded..."
```

### Pattern Learning

Based on research into habit formation (see `src/core/predictiveBehavior.js` legacy):

| Phase | Days | Confidence | What Happens |
|-------|------|------------|--------------|
| Collection | 1-7 | 40% | Observing patterns, no predictions |
| Formation | 8-21 | 40-60% | Patterns emerging, low confidence |
| Established | 21+ | 60-80% | Reliable predictions based on consistency |

### Reinforcement Learning

The system improves via feedback:

```typescript
// User found the surfaced memory useful
await memory_feedback({ patternId: "xxx", action: "used" });    // +1.0 reward

// User ignored it
await memory_feedback({ patternId: "xxx", action: "ignored" }); // -0.1 reward

// User explicitly dismissed it
await memory_feedback({ patternId: "xxx", action: "dismissed" }); // -0.5 reward
```

Patterns with consistently negative feedback are down-weighted.

### Example: Morning Briefing

```typescript
// Call day_outlook with your calendar
const outlook = await day_outlook({
  calendar: [
    { title: "Standup", startTime: "2024-01-15T09:00:00", attendees: ["Sarah", "Mike"] },
    { title: "1:1 with Jake", startTime: "2024-01-15T14:00:00", attendees: ["Jake"] },
  ]
});

// Response:
{
  "greeting": "Good morning, ready for Monday?",
  "outlook": "2 scheduled events. First up: Standup at 9:00 AM.",
  "insights": [
    "Tracking 12 established patterns with 73% average confidence.",
    "3 predicted context switches today based on your patterns."
  ],
  "upcomingContextSwitches": [
    {
      "time": "8:45 AM",
      "confidence": "78%",
      "briefingsNeeded": ["Sarah", "Mike"],
      "topicsLikely": ["sprint velocity", "payment bug", "Q4 planning"],
      "trigger": "Standup"
    }
  ]
}
```

---

## Framework Examples

### Python: AI Agent with Memory

```python
# pip install memorable-sdk anthropic

from memorable import MemorableClient, ContextFrame
from anthropic import Anthropic

# Initialize
memory = MemorableClient(
    mongo_uri="mongodb://localhost:27017/memorable",
    user_id="agent-001"
)
claude = Anthropic()

# Set context when starting a task
memory.set_context(
    location="vscode",
    activity="coding",
    project="payment-service"
)

# Store memories during conversation
memory.store(
    "User wants to refactor the PaymentProcessor class to use async/await",
    context={"file": "src/payments/processor.py", "priority": "high"}
)

# Get relevant context for the current task
relevant = memory.whats_relevant()
print(f"Related memories: {len(relevant.memories)}")
print(f"Open tasks: {len(relevant.open_loops)}")

# Build context-aware prompt
system_prompt = f"""You are a coding assistant with memory.

Current context:
- Project: {relevant.context.project}
- Recent decisions: {relevant.recent_decisions}
- Open tasks: {[l.description for l in relevant.open_loops]}

Previous relevant work:
{chr(10).join([m.text for m in relevant.memories[:5]])}
"""

# Query with context
response = claude.messages.create(
    model="claude-sonnet-4-20250514",
    system=system_prompt,
    messages=[{"role": "user", "content": "Continue the refactoring"}]
)

# Track commitments automatically
memory.store(response.content[0].text)  # Extracts action items automatically
```

### Python: Meeting Assistant

```python
from memorable import MemorableClient

memory = MemorableClient(user_id="user-123")

# Before meeting with Sarah
briefing = memory.get_briefing("Sarah Chen")

print(f"""
MEETING BRIEFING: Sarah Chen
============================
Last interaction: {briefing.last_interaction}
Relationship trend: {briefing.engagement_trend}

YOU OWE HER:
{chr(10).join([f"  - {l.description}" for l in briefing.you_owe_them])}

SHE OWES YOU:
{chr(10).join([f"  - {l.description}" for l in briefing.they_owe_you])}

HER UPCOMING EVENTS:
{chr(10).join([f"  - {e.description} ({e.event_date})" for e in briefing.upcoming_events])}

SENSITIVITIES:
{chr(10).join([f"  - {s}" for s in briefing.sensitivities])}
""")

# During meeting - set context
memory.set_context(people=["Sarah Chen"], activity="meeting")

# After meeting - store notes (auto-extracts commitments)
memory.store("""
Met with Sarah about Q4 planning.
- She'll send the budget spreadsheet by Friday
- I need to review the API proposal by next Tuesday
- Her team is stressed about the reorg, be supportive
- Daughter Emma starts kindergarten next week
""")

# Check what got extracted
status = memory.get_status()
print(f"Open loops created: {status.open_loops_count}")
```

### TypeScript: Express Middleware

```typescript
// npm install @memorable/sdk express

import { MemorableClient, contextMiddleware } from '@memorable/sdk';
import express from 'express';

const app = express();
const memory = new MemorableClient({
  mongoUri: process.env.MONGODB_URI,
});

// Add memory context to all requests
app.use(contextMiddleware(memory));

// API endpoint with memory
app.post('/api/chat', async (req, res) => {
  const { message, userId, conversationId } = req.body;

  // Get relevant context
  const context = await memory.setContext(userId, {
    activity: 'chat',
    metadata: { conversationId }
  });

  // Store the user message
  await memory.store(userId, message, {
    source: 'user',
    conversationId
  });

  // Build context-aware response
  const relevant = await memory.recall(userId, message, { limit: 5 });

  // ... generate response with context ...

  // Store assistant response (extracts commitments)
  await memory.store(userId, response, {
    source: 'assistant',
    conversationId
  });

  res.json({ response, context: context.suggestedTopics });
});

// Health endpoint
app.get('/health', memory.healthMiddleware());

// Metrics endpoint (Prometheus compatible)
app.get('/metrics', memory.metricsMiddleware());

app.listen(3000);
```

### TypeScript: Project-Aware Coding Assistant

```typescript
import { MemorableClient } from '@memorable/sdk';
import * as vscode from 'vscode';

const memory = new MemorableClient({
  mongoUri: process.env.MONGODB_URI,
  userId: 'developer-1'
});

// When switching files
vscode.window.onDidChangeActiveTextEditor(async (editor) => {
  if (!editor) return;

  const filePath = editor.document.fileName;
  const project = vscode.workspace.name;

  // Update context
  const context = await memory.setContext({
    location: 'vscode',
    activity: 'coding',
    metadata: {
      file: filePath,
      project,
      language: editor.document.languageId
    }
  });

  // Show relevant memories in sidebar
  if (context.relevantMemories.length > 0) {
    showMemorySidebar(context.relevantMemories);
  }
});

// Store decisions and learnings
async function rememberDecision(decision: string, rationale: string) {
  await memory.store(
    `DECISION: ${decision}\nRATIONALE: ${rationale}`,
    {
      tags: ['decision', 'architecture'],
      project: vscode.workspace.name
    }
  );
}

// Query past decisions
async function getRelatedDecisions(topic: string) {
  return memory.recall(topic, {
    tags: ['decision'],
    project: vscode.workspace.name,
    limit: 10
  });
}
```

---

## Behavioral Identity (Stylometry Engine)

**Know who you're talking to without login credentials.** MemoRable uses **proven stylometry methods from authorship attribution research** to learn each user's unique communication fingerprint. Character n-grams, function word frequencies, and syntactic complexity patterns create a highly accurate behavioral signature. After 50+ interactions, it can identify users by *how* they communicate with **90%+ accuracy**.

### How It Works

```
User Input: "hey can u check the payment thing from yesterday"

┌──────────────────────────────────────────────────────────────────┐
│              STYLOMETRY-BASED BEHAVIORAL FINGERPRINT              │
├──────────────────────────────────────────────────────────────────┤
│  Character N-grams (Most Discriminative - 25% weight) ★          │
│  ├─ Top 3-grams: "the", " ca", "can", "an ", "n u", " u "       │
│  ├─ N-gram signature: sig_7k2m9x (unique to this user)          │
│  └─ Cosine similarity match: 0.94                               │
│                                                                  │
│  Function Words (Classical Stylometry - 20% weight) ★            │
│  ├─ Pronoun preference: "u" over "you" (93%)                    │
│  ├─ Conjunction style: minimal ("and" < average)                │
│  └─ Function word signature: sig_3p8q2a                         │
│                                                                  │
│  Vocabulary Features (15% weight)                                │
│  ├─ Hapax ratio: 0.72 (uses unique words)                       │
│  ├─ Type-token ratio: 0.85 (rich vocabulary)                    │
│  └─ Avg syllables: 1.4 (simple word choice)                     │
│                                                                  │
│  Syntactic Complexity (15% weight)                               │
│  ├─ Avg sentence length: 8.3 words                              │
│  ├─ Clause complexity: 0.12 (simple structures)                 │
│  ├─ Punctuation style: light                                    │
│  └─ Ellipsis usage: false, Semicolon usage: false               │
│                                                                  │
│  Style Features (10% weight)                                     │
│  ├─ Formality score: 0.23 (informal)                            │
│  ├─ Contraction ratio: 0.15 (moderate)                          │
│  └─ Number style: numeric                                        │
│                                                                  │
│  Temporal Patterns (10% weight)                                  │
│  ├─ Active hours: 9am-6pm EST                                   │
│  └─ Peak activity: Tuesday/Thursday                              │
│                                                                  │
│  ★ = Research-proven most discriminative features                │
│                                                                  │
│  OVERALL CONFIDENCE: 94% → User: alex@company.com               │
└──────────────────────────────────────────────────────────────────┘
```

### Stylometry Signals (Research-Based Weights)

Based on authorship attribution research showing **90%+ accuracy** with character n-grams and function word analysis:

| Signal Type | What We Analyze | Weight | Why It Works |
|-------------|-----------------|--------|--------------|
| **Char N-grams** ★ | Character trigram frequencies | 25% | Most discriminative single feature (proven by CNN research) |
| **Function Words** ★ | Pronoun, preposition, conjunction usage | 20% | Classical stylometry gold standard |
| **Vocabulary** | Hapax ratio, type-token ratio, syllables | 15% | Lexical richness indicators |
| **Syntax** | Sentence length, comma/semicolon usage, clause complexity | 15% | Syntactic fingerprint |
| **Style** | Formality, contractions, emoji, list usage | 10% | Writing style preferences |
| **Timing** | Active hours, day patterns | 10% | Behavioral habits |
| **Topics** | Subject preferences, frequent terms | 5% | Context (less stable) |

★ = Research-proven most discriminative features

### Use Cases

**1. Seamless Multi-Device Experience**
```python
# User switches from laptop to phone mid-conversation
# MemoRable recognizes them by communication style, not just session token
result = memorable.identify_user(message_text)
# → {"userId": "alex@company.com", "confidence": 0.94, "signals": [...]}
```

**2. Anomaly Detection**
```python
# Alert when behavior doesn't match known patterns
if result.confidence < 0.5:
    # Possibly compromised account or new user
    trigger_verification()
```

**3. Personalization Without Login**
```python
# First message in a session - no auth yet
# MemoRable can still personalize based on detected identity
briefing = memorable.get_briefing_for_detected_user(message_text)
```

### Privacy & Consent

- Behavioral signatures are **local to your deployment** - never shared
- Users can **view their fingerprint** and **opt out** of behavioral tracking
- All signals are derived from **content they voluntarily provide**
- Compliant with GDPR "legitimate interest" for security purposes

### Metrics Dashboard

Real-time visibility into stylometry-based behavioral learning. Call `behavioral_metrics` to see:

```
╔══════════════════════════════════════════════════════════════════════╗
║           BEHAVIORAL IDENTITY METRICS (Stylometry Engine)            ║
║                     Time Range: 24h                                  ║
╠══════════════════════════════════════════════════════════════════════╣
║  LEARNING PROGRESS                                                    ║
║  ┌────────────────────────────────────────────────────────────────┐  ║
║  │ Users with fingerprints:   47                                  │  ║
║  │ Ready for identification:  38 (≥50 samples)                    │  ║
║  │ Avg samples per user:      72                                  │  ║
║  │                                                                │  ║
║  │ Progress: ██████████████████████████████  144%                 │  ║
║  └────────────────────────────────────────────────────────────────┘  ║
╠══════════════════════════════════════════════════════════════════════╣
║  IDENTIFICATION ACCURACY                                              ║
║  ┌────────────────────────────────────────────────────────────────┐  ║
║  │ Total predictions:    892                                      │  ║
║  │ With feedback:        456                                      │  ║
║  │                                                                │  ║
║  │ Hit Rate:  ██████████████████████  91.4%                      │  ║
║  │ Miss Rate: ██░░░░░░░░░░░░░░░░░░░░   8.6%                      │  ║
║  └────────────────────────────────────────────────────────────────┘  ║
╠══════════════════════════════════════════════════════════════════════╣
║  CONFIDENCE DISTRIBUTION                                              ║
║  ┌────────────────────────────────────────────────────────────────┐  ║
║  │  0-20%  ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░   12                     │  ║
║  │ 20-40%  ▓▓░░░░░░░░░░░░░░░░░░░░░░░░░░   34                     │  ║
║  │ 40-60%  ▓▓▓▓░░░░░░░░░░░░░░░░░░░░░░░░   67                     │  ║
║  │ 60-80%  ▓▓▓▓▓▓▓▓▓░░░░░░░░░░░░░░░░░░░  156                     │  ║
║  │ 80-100% ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  623                     │  ║
║  └────────────────────────────────────────────────────────────────┘  ║
╠══════════════════════════════════════════════════════════════════════╣
║  STYLOMETRY SIGNAL STRENGTH (proven authorship attribution)          ║
║  ┌────────────────────────────────────────────────────────────────┐  ║
║  │ Char N-grams   ██████████████████████  94% ★                  │  ║
║  │ Function Words █████████████████████░  91% ★                  │  ║
║  │ Vocabulary     █████████████████████░  88%                    │  ║
║  │ Syntax         ██████████████████░░░░  82%                    │  ║
║  │ Style          ████████████████░░░░░░  67%                    │  ║
║  │ Timing         ██████████████░░░░░░░░  58%                    │  ║
║  │ Topics         ███████████░░░░░░░░░░░  45%                    │  ║
║  └────────────────────────────────────────────────────────────────┘  ║
║  ★ = Research-proven most discriminative features                     ║
╚══════════════════════════════════════════════════════════════════════╝
```

### MCP Tools (3 new tools)

| Tool | Description |
|------|-------------|
| `identify_user` | Analyze a message to identify user by behavioral patterns |
| `behavioral_metrics` | Get dashboard with learning progress, accuracy, signal strength |
| `behavioral_feedback` | Mark identification as correct/incorrect for learning |

### Configuration

```env
# Enable behavioral identity (default: true)
BEHAVIORAL_IDENTITY_ENABLED=true

# Minimum interactions before fingerprinting (default: 50)
BEHAVIORAL_MIN_SAMPLES=50

# Confidence threshold for identity match (default: 0.75)
BEHAVIORAL_CONFIDENCE_THRESHOLD=0.75

# Include in identity verification flow (default: false)
BEHAVIORAL_AUTH_ENABLED=false
```

---

## Mem0 Integration

MemoRable is designed to **extend** your existing Mem0 deployment, not replace it. Keep Mem0 for what it does best (vector storage and semantic search), and add MemoRable for context intelligence.

### Architecture: Mem0 + MemoRable

```
┌─────────────────────────────────────────────────────────────────┐
│                     Your AI Application                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌─────────────────────┐      ┌─────────────────────────────┐  │
│  │       Mem0          │      │        MemoRable            │  │
│  │  (Vector Layer)     │◄────►│   (Context Layer)           │  │
│  │                     │      │                             │  │
│  │  • Embeddings       │      │  • Salience scoring         │  │
│  │  • Semantic search  │      │  • Commitment tracking      │  │
│  │  • Vector storage   │      │  • Relationship graphs      │  │
│  │                     │      │  • Pre-meeting briefings    │  │
│  │                     │      │  • Predictive memory        │  │
│  │                     │      │  • MCP protocol             │  │
│  └─────────────────────┘      └─────────────────────────────┘  │
│           │                              │                       │
│           ▼                              ▼                       │
│  ┌─────────────────────┐      ┌─────────────────────────────┐  │
│  │   Vector DB         │      │    MongoDB/DocumentDB       │  │
│  │   (Pinecone/etc)    │      │    (shared or separate)     │  │
│  └─────────────────────┘      └─────────────────────────────┘  │
└─────────────────────────────────────────────────────────────────┘
```

### HybridMemory Class

```python
from memorable import MemorableClient
from mem0 import Memory as Mem0Memory

class HybridMemory:
    """
    Combines Mem0's vector search with MemoRable's context intelligence.
    Drop-in enhancement for existing Mem0 deployments.
    """

    def __init__(self, mongo_uri: str = None):
        self.memorable = MemorableClient(mongo_uri=mongo_uri)
        self.mem0 = Mem0Memory()

    def add(self, text: str, user_id: str, metadata: dict = None):
        # MemoRable: salience, commitments, relationships, timeline
        result = self.memorable.store(user_id, text, metadata)

        # Mem0: vector embeddings for semantic search
        self.mem0.add(text, user_id=user_id, metadata={
            **(metadata or {}),
            'salience_score': result.salience.score,
            'memory_id': result.memory_id,
            'has_commitments': len(result.open_loops_created) > 0
        })

        return result

    def search(self, query: str, user_id: str, **kwargs):
        # Semantic search via Mem0
        results = self.mem0.search(query, user_id=user_id, **kwargs)

        # Boost by MemoRable salience (important memories rank higher)
        for r in results:
            salience = self.memorable.get_salience(r['metadata']['memory_id'])
            r['boosted_score'] = r['score'] * 0.6 + (salience / 100) * 0.4

        return sorted(results, key=lambda x: x['boosted_score'], reverse=True)

    def get_briefing(self, user_id: str, person: str):
        """MemoRable exclusive: pre-conversation intelligence"""
        return self.memorable.get_briefing(user_id, person)

    def get_open_loops(self, user_id: str):
        """MemoRable exclusive: commitment tracking"""
        return self.memorable.list_loops(user_id)

    def set_context(self, user_id: str, **context):
        """MemoRable exclusive: context-aware memory surfacing"""
        return self.memorable.set_context(user_id, **context)
```

### AWS Deployment: Side-by-Side

If you have Mem0 running on AWS, add MemoRable to the same VPC:

```yaml
# Add to your existing docker-compose.yml or ECS task definition
memorable:
  image: ghcr.io/alanchelmickjr/memorable:latest
  environment:
    - MONGODB_URI=${DOCUMENTDB_URI}  # Share with existing DocumentDB
    - LLM_PROVIDER=bedrock           # Use same Bedrock as Mem0
  depends_on:
    - mem0  # Your existing Mem0 service
```

### Sync Existing Mem0 Memories

Enrich your existing Mem0 memories with salience scores:

```python
from memorable import MemorableClient
from mem0 import Memory

mem0 = Memory()
memorable = MemorableClient()

# Sync existing memories (non-destructive)
for mem in mem0.get_all(user_id="user-123"):
    memorable.store(
        user_id="user-123",
        text=mem['memory'],
        context={
            'synced_from': 'mem0',
            'original_id': mem['id'],
            'created_at': mem['created_at']
        }
    )
    # Update Mem0 with salience score
    mem0.update(mem['id'], metadata={'salience_synced': True})

print("Memories synced with salience enrichment")
```

---

## Deployment

### Local Development

```bash
git clone https://github.com/alanchelmickjr/memoRable.git
cd memoRable
npm install
npm run setup      # Auto-generates secure credentials
docker-compose up -d
npm test
```

---

### AWS One-Click Deploy

**Click the button. Choose provider. Wait 15 minutes. Done.**

[![Deploy to AWS](https://img.shields.io/badge/Deploy%20to-AWS-FF9900?style=for-the-badge&logo=amazon-aws)](https://console.aws.amazon.com/cloudformation/home#/stacks/quickcreate?templateUrl=https://memorable-cloudformation-templates.s3.us-east-1.amazonaws.com/memorable-stack.yaml&stackName=memorable)

| LLM Provider | What you need | Best for |
|--------------|---------------|----------|
| **Bedrock** (default) | Just AWS Account | SaaS (bill via AWS), enterprise, no API key management |
| **Anthropic** | AWS Account + [API Key](https://console.anthropic.com) | Self-hosted, direct API pricing |

**That's it.** The stack:
1. Creates VPC, databases, load balancer, auto-scaling
2. Configures Bedrock IAM permissions (or Anthropic secret)
3. Pulls the code from GitHub
4. Builds the Docker image
5. Deploys to ECS

Your URL appears in CloudFormation Outputs when complete.

#### Costs

| Size | Monthly Cost | Use Case |
|------|--------------|----------|
| Small | ~$150 | Development, testing |
| Medium | ~$400 | Small production |
| Large | ~$800 | Production with HA |

---

### AWS CI/CD Setup (OIDC - Recommended)

Secure, keyless authentication from GitHub Actions to AWS. No stored credentials.

<details>
<summary>Click to expand OIDC setup instructions</summary>

#### Step 1: Deploy OIDC Infrastructure (One-Time)

[![Deploy OIDC](https://img.shields.io/badge/Deploy-GitHub_OIDC-232F3E?style=for-the-badge&logo=amazon-aws)](https://console.aws.amazon.com/cloudformation/home#/stacks/quickcreate?templateUrl=https://memorable-cloudformation-templates.s3.us-east-1.amazonaws.com/github-oidc.yaml&stackName=memorable-github-oidc)

Or manually:
```bash
aws cloudformation create-stack \
  --stack-name memorable-github-oidc \
  --template-body file://cloudformation/github-oidc.yaml \
  --capabilities CAPABILITY_NAMED_IAM \
  --parameters ParameterKey=GitHubOrg,ParameterValue=YOUR_ORG \
               ParameterKey=GitHubRepo,ParameterValue=memoRable
```

#### Step 2: Add ONE GitHub Secret

| Secret | Value |
|--------|-------|
| `AWS_ACCOUNT_ID` | Your 12-digit AWS account ID (e.g., `123456789012`) |

That's it. No access keys, no rotating credentials, no security risks.

#### Step 3: Push and Deploy

Push to `main` and GitHub Actions automatically:
1. Authenticates via OIDC (keyless)
2. Builds Docker images
3. Pushes to ECR
4. Deploys via Terraform

</details>

<details>
<summary>Click to expand legacy access key instructions (not recommended)</summary>

#### Step 1: Create IAM User

```bash
# IAM → Users → Create User → "memorable-deploy"
# Attach: AmazonEC2FullAccess, AmazonECS_FullAccess, AmazonVPCFullAccess,
#         SecretsManagerReadWrite, AmazonElastiCacheFullAccess, AmazonDocDBFullAccess,
#         AmazonS3FullAccess, AmazonDynamoDBFullAccess, IAMFullAccess,
#         CloudWatchLogsFullAccess, AmazonEC2ContainerRegistryFullAccess,
#         ElasticLoadBalancingFullAccess
# Create access key → Download CSV
```

#### Step 2: Add GitHub Secrets

| Secret | Value |
|--------|-------|
| `AWS_ACCESS_KEY_ID` | From CSV |
| `AWS_SECRET_ACCESS_KEY` | From CSV |
| `ANTHROPIC_API_KEY` | `sk-ant-...` (only if using Anthropic provider) |

#### Step 3: Bootstrap & Deploy

```bash
aws configure
./scripts/terraform-bootstrap.sh staging

cd terraform
terraform init -backend-config="bucket=memorable-terraform-state-staging"
export TF_VAR_anthropic_api_key="sk-ant-xxx"
terraform apply -var-file="environments/staging.tfvars"
```

</details>

<details>
<summary>Click to expand: Hosting your own one-click deploy templates (for forks)</summary>

#### Template Hosting Setup

The one-click deploy buttons require CloudFormation templates hosted in S3 (GitHub raw URLs don't work with CloudFormation quickcreate).

**Option 1: Automatic (CI/CD)**

1. Deploy the OIDC stack (see above)
2. Add `AWS_ACCOUNT_ID` secret to your repo
3. Push to `main` - the `publish-templates.yml` workflow auto-creates the bucket and uploads templates

**Option 2: Manual**

```bash
# Create the template bucket
aws cloudformation deploy \
  --template-file cloudformation/template-bucket.yaml \
  --stack-name memorable-template-bucket \
  --parameter-overrides BucketName=YOUR-BUCKET-NAME

# Upload templates
./scripts/publish-templates.sh YOUR-BUCKET-NAME us-east-1
```

Then update the deploy button URLs in README.md:
```
https://console.aws.amazon.com/cloudformation/home#/stacks/quickcreate?templateUrl=https://YOUR-BUCKET-NAME.s3.us-east-1.amazonaws.com/memorable-stack.yaml&stackName=memorable
```

</details>

---

### AWS Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│                        AWS Cloud                                 │
│                                                                  │
│  ┌──────────┐     ┌──────────┐     ┌───────────────────────┐   │
│  │   ALB    │────▶│   ECS    │────▶│     Data Layer        │   │
│  │ (HTTPS)  │     │ Fargate  │     │  ┌─────────────────┐  │   │
│  └──────────┘     │          │     │  │   DocumentDB    │  │   │
│       │           │ • App    │     │  │   (MongoDB)     │  │   │
│       │           │ • Ingest │     │  ├─────────────────┤  │   │
│  ┌────▼─────┐     │          │     │  │  ElastiCache    │  │   │
│  │ Secrets  │     └──────────┘     │  │   (Redis)       │  │   │
│  │ Manager  │                      │  └─────────────────┘  │   │
│  └──────────┘                      └───────────────────────┘   │
│                                                                  │
│  VPC: 10.0.0.0/16 │ Private Subnets │ NAT Gateway │ Auto-scale │
└─────────────────────────────────────────────────────────────────┘
```

### Services

| Service | Port | Purpose |
|---------|------|---------|
| `memorable_app` | 3000 | Main application |
| `memorable_mcp_server` | stdio | MCP server for Claude Code |
| `memorable_ingestion_service` | 8001 | Memory ingestion API |
| `memorable_mongo` | 27017 | Document storage |
| `memorable_redis` | 6379 | Context frames, caching |
| `memorable_weaviate` | 8080 | Vector search |

---

## Core Concepts

### Salience Scoring

Every memory gets a 0-100 salience score calculated at capture time:

| Factor | Weight | Signals |
|--------|--------|---------|
| **Emotional** | 30% | Keywords (died, love, fired), sentiment intensity |
| **Novelty** | 20% | New people, locations, topics |
| **Relevance** | 20% | Your name, interests, goals, close contacts |
| **Social** | 15% | Relationship events, conflicts, vulnerability |
| **Consequential** | 15% | Action items, decisions, deadlines, money |

### Context Frames

Rolling window of what's happening NOW:
- **Location**: Where you are (park, office, VS Code)
- **People**: Who you're with or working with
- **Activity**: What you're doing (meeting, coding, relaxing)
- **Project**: What codebase/task you're in

When context changes, relevant memories automatically surface.

### Multi-Device Architecture (Brain-Inspired)

Same user on multiple devices? MemoRable handles it like your brain handles sensory data:

```
Phone (GPS)      → Location Stream  ─┐
Laptop (Calendar)→ Activity Stream  ─┼──▶ Context Integration ──▶ Unified "Now"
Smart Glasses   → Visual Stream    ─┤     (Thalamus-inspired)
Smart Watch     → Biometric Stream ─┘
```

**How it works:**
- Each device maintains its own context stream (like sensory subsystems)
- Contexts are fused using resolution strategies:
  - **Location**: Mobile wins (has GPS)
  - **People**: Merged from all devices
  - **Activity**: Most recent wins
- Device-specific Redis keys prevent race conditions
- Query `unified: true` to get the fused context

```typescript
// Phone reports location
set_context({ location: "coffee shop", deviceId: "iphone-123", deviceType: "mobile" })

// Laptop reports calendar context
set_context({ people: ["Sarah"], activity: "meeting", deviceId: "macbook-456", deviceType: "desktop" })

// Get unified view across all devices
whats_relevant({ unified: true })
// → { location: "coffee shop", people: ["Sarah"], activity: "meeting", activeDevices: 2 }
```

**Sensor types supported**: location, audio, visual (LIDAR), calendar, activity, biometric, environment, social, semantic.

### Open Loops

Automatic tracking of commitments:
- **You owe them**: Things you promised to do
- **They owe you**: Things promised to you
- **Mutual**: Shared commitments

### Memory Lifecycle

```
active → archived → suppressed → deleted (30-day retention)
       ↑
    restore
```

### Pattern Learning (21-Day Rule)

Based on habit formation research:
- Patterns need 21 days to form reliably
- Confidence starts at 40%, ramps to 80% with consistency
- Post-formation: confidence = (occurrences / days) × 0.8
- RL feedback adjusts pattern weights over time

---

## Testing

```bash
# Run all Jest tests
npm test

# Run salience service unit tests (standalone)
npx tsx scripts/test_salience.ts

# Example output:
# === Anticipation Service Tests ===
# ✓ THRESHOLDS are correctly defined
# ✓ WINDOWS are correctly defined (21 days for pattern formation)
# ✓ getTimeOfDay returns correct values
# ✓ calculatePatternConfidence: Day 1 (brand new pattern)
# ✓ calculatePatternConfidence: Day 21 with 21 occurrences (fully formed)
# ✓ calculateRewardSignal: Mixed feedback
# === Test Summary ===
# Passed: 12
# Failed: 0
```

---

## Project Structure

```
memorable/
├── src/services/
│   ├── mcp_server/              # MCP server for Claude Code
│   │   └── index.ts             # 18 MCP tools
│   ├── salience_service/        # Core memory intelligence
│   │   ├── index.ts             # Main exports
│   │   ├── anticipation_service.ts  # Predictive memory (21-day learning)
│   │   ├── context_frame.ts     # Rolling context windows
│   │   ├── memory_operations.ts # Forget/reassociate/export
│   │   ├── feature_extractor.ts # LLM feature extraction
│   │   ├── salience_calculator.ts
│   │   ├── open_loop_tracker.ts
│   │   ├── relationship_tracker.ts
│   │   ├── briefing_generator.ts
│   │   ├── retrieval.ts
│   │   ├── adaptive_learning.ts
│   │   ├── metrics.ts           # Prometheus metrics
│   │   └── startup.ts           # Health checks
│   ├── ingestion_service/       # Memory ingestion API
│   └── embedding_service/       # Vector embeddings
├── scripts/
│   ├── setup.js                 # Auto-credential generation
│   ├── aws-setup.sh             # AWS infrastructure setup
│   └── test_salience.ts         # Unit tests
├── .github/workflows/
│   ├── ci.yml                   # CI pipeline
│   └── deploy-aws.yml           # AWS deployment
├── docker-compose.yml           # Full stack
└── docs/
```

---

## API Endpoints

### Health & Metrics

```bash
GET /health/live      # Liveness probe
GET /health/ready     # Readiness probe
GET /health/startup   # Startup probe
GET /health           # Full status
GET /metrics          # Prometheus metrics
```

### Ingestion

```bash
POST /api/ingest/memory
{
  "text": "Meeting notes...",
  "userId": "user-123",
  "context": {
    "location": "office",
    "people": ["Sarah", "Mike"]
  }
}
```

---

## Environment Variables

```bash
# Required
MONGODB_URI=mongodb://localhost:27017/memorable

# LLM Provider (choose one)
# Option 1: AWS Bedrock (recommended for AWS deployment - no API key needed)
LLM_PROVIDER=bedrock          # or set USE_BEDROCK=true
AWS_REGION=us-east-1          # Bedrock uses IAM authentication

# Option 2: Anthropic Direct API
LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-xxx

# Option 3: OpenAI
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-xxx

# Auto-detection (when LLM_PROVIDER not set):
# - Running in AWS (Lambda/ECS)? → Bedrock
# - ANTHROPIC_API_KEY set? → Anthropic
# - OPENAI_API_KEY set? → OpenAI

# Optional
REDIS_URL=redis://localhost:6379
WEAVIATE_URL=http://localhost:8080
MCP_USER_ID=default
LOG_LEVEL=INFO
```

---

## Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push (`git push origin feature/amazing`)
5. Open Pull Request

---

## License

MIT License - see [LICENSE](LICENSE)

---

## Links

- [MCP Server Documentation](./src/services/mcp_server/README.md)
- [Salience Service Documentation](./src/services/salience_service/README.md)
- [Claude.ai Integration Guide](./docs/claude-ai-integration.md)
- [Example Prompts](./docs/example-prompts.md)
- [Privacy Policy](./PRIVACY.md)
- [API Reference](./docs/api-reference.md)
- [Deployment Guide](./docs/deployment-guide.md)
